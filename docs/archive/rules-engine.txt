Great—here’s a concise, phased plan that gets you real wins fast without breaking existing flows. I split it into Phase 1 (minimal code changes with immediate value) and Phase 2 (schema + rules engine for UNO-level complexity).

Phase 1 — Make grouped rules actually count
Success criteria

Grouped requirements are evaluated using the existing group evaluators.
Plan courses get auto-assigned to groups when possible.
Zero-credit, course-count-only groups (e.g., exit exam) show as complete.
Responses preserve current shapes but add group details without breaking the UI.
Scope and steps

Wire grouped evaluator into progress
For requirement_type='grouped', call ProgramRequirement.evaluate_completion() and use result.satisfied, credits_earned, and group_results.
Aggregate alongside simple requirements so the API keeps totalCredits, completedCredits, status for each requirement.
Preserve existing fields; add non-breaking extras like group_results.
Auto-assign courses to groups
When adding/updating a PlanCourse, if the plan has a target program, find any RequirementGroup in that program whose GroupCourseOption matches course.code (and institution when present), then set requirement_group_id.
If multiple groups match: pick the is_preferred option first; otherwise choose the group with the strictest courses_required or the earliest priority; record a note for auditability.
If none match, leave requirement_group_id null.
Return grouped details in API
Enrich GET plan and progress endpoints to include group_results for grouped requirements, including:
groups satisfied vs not
courses_used (with ids, codes, credits)
course-count-only completions (zero-credit groups) reflected as status=met
Tests
Add unit tests for:
grouped evaluation (courses_required met/not met; credits_required met/not met)
zero-credit group completion (e.g., BIOS 4010)
auto-assignment exact match, multiple matches, no match
regression for simple requirements unchanged
Authoring/docs
Update CSV authoring guide to emphasize:
grouped requirements enforce literal options
use separate groups to avoid mixing sequence tracks (e.g., PHYS 103x vs 106x)
how is_preferred affects auto-assignment
Rollout and safeguards
Add a feature flag (env var) to toggle the new grouped evaluation in progress while testing.
Log auto-assignment ambiguities and unmatched courses to help data cleanup.
What Phase 1 won’t address (explicitly)

Level/lab/type counts or caps (e.g., “min 17 credits BIOS at 3000/4000 lecture/lab,” “min 2 labs,” “max 7 research/seminar”).
Grade thresholds and language-sequence coherence.
Criteria-based groups (subject/level/pattern) instead of enumerated lists.
Phase 2 — Model and enforce UNO-level constraints
Add course tags and attributes
Extend Course with attributes/tags:
has_lab (bool), course_type (enum: lecture, lecture_lab, lab_only, research, seminar)
optional CourseTag table for flexible labels (e.g., “research,” “seminar”)
Backfill from CSVs or a small admin tool.
Requirement constraints model
New RequirementConstraint table:
fields: requirement_id, type (min_level_credits, min_tag_courses, max_tag_credits, min_4000_courses, same_sequence, min_grade, substitution_set, etc.), params (JSON)
optional scope filters (subject_code=‘BIOS’, level_min=3000)
Extend evaluators
After base/group satisfaction, apply constraints and produce:
satisfied: bool
reasons with shortcodes (e.g., not_enough_3000_level, lab_courses_short_by_1, research_cap_exceeded_by_2cr)
tallies for advisor UX
CSV and criteria-based groups
Allow groups to be defined with criteria columns:
subject_code, level_min, level_max, has_lab, include_tags, exclude_tags
Keep existing course_option for exact lists; criteria acts as a generator or validation rule.
Substitutions and sequences
Introduce “sequence_id” for courses in a track and a constraint “choose N from one sequence.”
Add “substitution_set” to define equivalent paired paths (e.g., MATH 1125/1126 vs 2114/2124).
Advisor UX improvements
In progress/audit payloads, include human-readable “why not met,” and top suggestions that satisfy remaining constraints.
Add a compact “constraint summary” per requirement.
Acceptance checkpoints
Phase 1 demo data: Use program_requirements_formatted.csv and the UNO target CSV. Validate:

Grouped categories reflect accurate “met/part/none” even with zero-credit items.
Auto-assignment kicks in when adding courses by code.
API backward compatibility holds (fields preserved).
Phase 2 demo: Start with BIOS electives constraints (level/lab/research caps). Show a report that flags unmet counts and suggests specific courses that satisfy missing tags/levels.